{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3ef33",
   "metadata": {},
   "outputs": [],
   "source": "# Get secrets from Databricks secret scope\nS3_BUCKET = dbutils.secrets.get(scope=\"fmp_scope\", key=\"S3_BUCKET\")\nAWS_ACCESS_KEY_ID = dbutils.secrets.get(scope=\"fmp_scope\", key=\"AWS_ACCESS_KEY_ID\")\nAWS_SECRET_ACCESS_KEY = dbutils.secrets.get(scope=\"fmp_scope\", key=\"AWS_SECRET_ACCESS_KEY\")\n\n# Configuration\nS3_RAW_PREFIX = \"raw\"\nAWS_REGION = \"us-east-1\"\n\nprint(f\"S3 Bucket: {S3_BUCKET}\")\nprint(f\"S3 Raw Prefix: {S3_RAW_PREFIX}\")\nprint(f\"AWS Region: {AWS_REGION}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665918b7",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": "%sql\n-- Create storage credential using AWS access keys\nCREATE STORAGE CREDENTIAL IF NOT EXISTS stock_s3_credential\nWITH (\n    AWS_ACCESS_KEY_ID = SECRET('fmp_scope', 'AWS_ACCESS_KEY_ID'),\n    AWS_SECRET_ACCESS_KEY = SECRET('fmp_scope', 'AWS_SECRET_ACCESS_KEY')\n)\nCOMMENT 'S3 access for stock data pipeline using access keys'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0705c4d",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": "%sql\n-- Verify storage credential was created\nDESCRIBE STORAGE CREDENTIAL stock_s3_credential"
  },
  {
   "cell_type": "code",
   "id": "7hxt8xxh6yh",
   "source": "%sql\n-- Create external location for raw stock data\nCREATE EXTERNAL LOCATION IF NOT EXISTS stock_raw_data\nURL 's3://${S3_BUCKET}/raw/'\nWITH (STORAGE CREDENTIAL stock_s3_credential)\nCOMMENT 'External location for raw stock price data ingested from FMP API'",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}