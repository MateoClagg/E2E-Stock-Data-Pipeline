{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da6a5497-a0d1-41ff-8fe1-fb162e7dac8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set paths to external location (s3 bucket)\n",
    "bucket = \"s3://stock-pipeline-data-dev-mc\"\n",
    "\n",
    "raw_price_path = f\"{bucket}/raw/prices/\"\n",
    "bronze_price_path = f\"{bucket}/bronze/prices_v2/\"               # actual Delta storage\n",
    "ckpt_price_path = f\"{bucket}/_checkpoints/bronze_prices\"     # streaming checkpoints\n",
    "ckpt_schema_path = f\"{bucket}/_checkpoints/bronze_prices_schema\"  # schema evolution\n",
    "\n",
    "catalog = \"stock_pipeline\"\n",
    "schema  = \"bronze\"\n",
    "table   = f\"{catalog}.{schema}.prices_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d9b131c-1479-4001-82d1-35164d90b041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Auto-loader reads from raw price data\n",
    "df = (spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\",\"parquet\")\n",
    "        .option(\"ignoreMissingFiles\", \"true\")\n",
    "        .option(\"cloudFiles.inferColumnTypes\",\"true\")\n",
    "        .option(\"cloudFiles.includeExistingFiles\",\"false\")   # use false for daily ingest\n",
    "        .option(\"cloudFiles.schemaLocation\", ckpt_schema_path)\n",
    "        .load(raw_price_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb0c2ea8-8dc1-4ebc-b13e-78ec74bceb16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Schema\n",
    "from pyspark.sql.functions import col, to_date, year, month\n",
    "\n",
    "df_norm = (df\n",
    "    .withColumn(\"symbol\", col(\"symbol\").cast(\"string\"))\n",
    "    .withColumn(\"as_of_date\", to_date(col(\"as_of_date\")))  # New column name\n",
    "    .withColumn(\"open\", col(\"open\").cast(\"double\"))\n",
    "    .withColumn(\"high\", col(\"high\").cast(\"double\"))\n",
    "    .withColumn(\"low\", col(\"low\").cast(\"double\"))\n",
    "    .withColumn(\"close\", col(\"close\").cast(\"double\"))\n",
    "    .withColumn(\"volume\", col(\"volume\").cast(\"double\"))\n",
    "    .select(\n",
    "      \"symbol\", \"as_of_date\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "      \"fetched_at\", \"source\", \"endpoint\", \"request_id\", \"file_hash\"  # Keep metadata\n",
    "    )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82eb6711-87a1-4039-8559-bda41395347e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# write to delta table\n",
    "q = (df_norm.writeStream\n",
    "      .format(\"delta\")\n",
    "      .outputMode(\"append\")\n",
    "      .option(\"checkpointLocation\", f\"{ckpt_price_path}/stream\")\n",
    "      .option(\"mergeSchema\",\"true\")\n",
    "      .option(\"optimizeWrite\", \"true\")  # ← Add: Bins small files\n",
    "      .option(\"autoCompact\", \"true\")     # ← Add: Compacts automatically\n",
    "      .trigger(availableNow=True)  # run-to-completion, then stop\n",
    "      .start(bronze_price_path)\n",
    ")\n",
    "\n",
    "q.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a81e8f77-351e-4a03-a6dd-0cfe45fd5d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table}\n",
    "    USING DELTA\n",
    "    LOCATION '{bronze_price_path}'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    SET TBLPROPERTIES ('delta.columnMapping.mode' = 'name')\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    OPTIMIZE delta.`{bronze_price_path}`\n",
    "    ZORDER BY (as_of_date, symbol)\n",
    "    \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6313959633156889,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_prices_auto_loader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
